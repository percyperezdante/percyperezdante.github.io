[
{
	"uri": "http://example.org/projects/",
	"title": "Projects",
	"tags": [],
	"description": "",
	"content": "Projects This page list some of the small projects I worked in during my free time in ad-hoc mode.\nWawa A baby monitoring trail. Wawa, from the Aymara Baby, is a project inspired in how to help a mum to keep one eye in her newborn baby while she is executing some activity inside the house, in particular in the case when the newborn baby is sleeping and you want to monitor your baby. Qilquiri Qilquiri, from the Aymara Writer, is a helper that generates snipes of common Java-base code from a Vim session. For example, create a class signature by just presing two keys. Achacachi Achachachi is the name of a small town located on the Altiplano in the South American Andes. This project is a small set of scripts to re-deploy my laptop configuration. When my laptop broken or simply needs to be re-installed, \u0026#34;I need to back to Achacachi\u0026#34; to get all the configuration back as before. "
},
{
	"uri": "http://example.org/devops/",
	"title": "DevOps",
	"tags": [],
	"description": "",
	"content": "Devops Infrastructure as a code  Building images: This section presents examples of building images using Packer from HashiCorp.  Cloud Computing  GCP notes Short notes from GCP training sessions.  "
},
{
	"uri": "http://example.org/sre/",
	"title": "SRE",
	"tags": [],
	"description": "",
	"content": "Site Reliability Engineering This page is in its initial stage. I am trying to collect and read references which can be found at references.\n"
},
{
	"uri": "http://example.org/notes/",
	"title": "Notes",
	"tags": [],
	"description": "",
	"content": "General notes This page containts brief examples and explanation of different topics of interests from my students.\nMore details will be added gradually.\nA K  Kubernetes  G  Golang  "
},
{
	"uri": "http://example.org/teaching/resources/",
	"title": "Resources",
	"tags": [],
	"description": "",
	"content": "This site present a list of resources shared by or to my students during the teaching and training sessions. I am placing here as a way to remember them and share with people with similar interest.\nA M  Math for programmers by Simon Robinson  This course covers the maths behind how your computer stores and manipulates data. You\u0026#39;ll learn how to read binary and hexadecimal, how both integers and floating point numbers are stored and the limitations of using them. Advice on best practices... "
},
{
	"uri": "http://example.org/devops/gcp/",
	"title": "GCP",
	"tags": [],
	"description": "",
	"content": "Googgle Cloud Platform Notes. This section contains notes about different GCP topics.\nGoogle Cloud Platform Fundamentals: Core Infrastructure "
},
{
	"uri": "http://example.org/tools/",
	"title": "Tools",
	"tags": [],
	"description": "",
	"content": "Tools This page is just to remember the references of the tools I think are useful and the tools recommened by friends. It helps me to not searching it again from scratch and also safe time when a friend ask me for more information.\nCategories  Browsing and plugins Text editors Terminals  "
},
{
	"uri": "http://example.org/reproducibility/",
	"title": "Reproducibility",
	"tags": [],
	"description": "",
	"content": "Reproducibility The idea to promote reproducibility was inspired by my last research work, nMANET. At many points of my research, I was stopped by many issues, which were required help from experts. Helpers need to reproduce the issue locally, which not always is a trivial task. However, if there is a method to let the helper reproduce the issue in a fast and painless manner, the discusion of the problem became more predominant compared with the effort of reproduce the problem. I am planning to fill this page with more details during my free time, which is the reason of why I tag this site as under construction. "
},
{
	"uri": "http://example.org/teaching/",
	"title": "Teaching",
	"tags": [],
	"description": "",
	"content": "Teaching This site present my teaching and knowledge transfer activities inside and outside the university. Some resources are showed in here in case of interest.\n2020  A practical overview of Vagrant A technical session for Jenkins and Vagrant Using plugins in Jenkins  2019  Introduction to Continuous Integration and pipelines. Introduction to Jenkins  2017/2018 academic teaching activities St-Andrews University. Tutorials: CS2006 Advanced Programming Projects Demonstrations: CS2002 Computer architectures CS2006 Advanced Programming Projects Lecturer assistance: CS3102 Data Communications and Networks. CS2002 Computer architectures CS2006 Advanced Programming Projects  Past years academic teaching activities St-Andrews University. Semester One 2017/2018 Tutorials CS1002 Object Oriented Programming CS1005 Computer Science in Everyday Life CS1003 Programming with Data   Semester One 2017/2018 Demonstrations: CS1002 Object Oriented Programming Exercise classes: CS1002 Object Oriented Programming CS2003 The Internet and the Web: Concepts and Programming   Semester Two 2016/2017 Tutorials: CS1003 Programming with Data Demonstrations: CS1006 Programming Projects CS2002 Computer Systems CS2006 Advanced Programming Projects   Semester One 2016/2017 Tutorials: CS1005 Computer Science in Everyday Life Demonstrations: CS1002 Object Oriented Programming CS2003 The Internet and the Web: Concepts and Programming  "
},
{
	"uri": "http://example.org/research/",
	"title": "Research",
	"tags": [],
	"description": "",
	"content": "Research This section presents the research topics of interest.\nnMANET nManet is the short name for NDN applied in Manets. NDN stands for Named Data Neworking and Manets stands for Mobile Ad-hoc Networks. In this research, nMANET aims to offer an alterntive to ad-hoc mobile exchange of information in emergency scenarios.\n"
},
{
	"uri": "http://example.org/blog/",
	"title": "Blog",
	"tags": [],
	"description": "",
	"content": "Blog This blog is empty for now, but I am planning to write one blog about:\n Cooking rice. Share my life location. Books I read  Hope it come soon.\n"
},
{
	"uri": "http://example.org/funding/",
	"title": "Funding",
	"tags": [],
	"description": "",
	"content": "Demetria \u0026amp; Mario foundation This is a foundation created by Demetria Inocencia Aruni Rojas de Perez and Mario Hermogenes Perez Limachi with the intention to support education and culture for Aymara children in the community of Viacha in La Paz - Bolivia. The Demetria \u0026amp; Mario foundation is in its initial stage and it is planned to start its first intervention by the end of 2020.\nI decided to join this foundation after the talk provided by the founders in Viacha-Bolivia, which explained the importance to invest in education of Aymara Children as a way to preserve Aymara culture and let the future of Viacha coexists with new technoligies that can enhance the life standards of people within the community.\nMore details are planned to appear in the comming months and if you are interested to join, please feel free to contact me.\n"
},
{
	"uri": "http://example.org/",
	"title": "Home",
	"tags": [],
	"description": "",
	"content": "Welcome My name is Percy, and this site has a minimal content about my interests, activities, and notes I recorded for myself or for people with similar interests.\nContact  percyperezdante [at] gmail (dot) com Github Linkedin, Vagrant Cloud Twitter: @percyperezd  Interests My main interests include to develop, experiment and test new technologies related to:\n nMANET Reproducibility Teaching Automation Continuous Integration and Continuous Delivery Site Reliability Engineering DevOps Software Development Enginering Cloud computing Distributed systems Security  NOTE: nMANET is an approach that intends to offer an alternative to solve the limitations of Mobile Ad-hoc Networks in emergency scenarios such as earthquakes and social riots.\nnMANET intends to show whether future Internet architectures such as Name Data based Networking protocol can be applied in Mobila Ad-hoc networks. To achieve this, I am designing, implementing and testing JNFD, which is the prototype of nMANET, and that is functional in Andriod and Linux base mobile devices. The source code of JNFD is open source and it has been tested in smartphones such as MotoE, MotoG, and Samsumg Note4, and also in laptops and through JNFD simulators such as Mini-JNFD.\nActivities   Sports. I like to play football and basketball, but also I often swim. I currenly swiming for the Diabetes UK charity, swim22. We formed a great team of colleges who are willing to swim approximatelly 230 Km all together. As a team we would love to have your contributions if possible of course.\n  Devops days Edinburgh 2020. I am member of the organizers for the 2020 Devops days in Edinburgh. Devops days happen here in Edinburhg once a year and is an international conference that include technical talks about software development, IT infrastructure operations, and a mix of them.\n  Notes This section contains a set of basic tutorials I wrote for my students. They are simple notes I took from books and online resources. These notes are grouped in the following categories.\n  Minimal infrastructure\n  Software Development\n  Infrastrucuture as a code\n  Devops \u0026amp; SRE\n  "
},
{
	"uri": "http://example.org/notes/kubernetes/",
	"title": "Kubernetes",
	"tags": [],
	"description": "",
	"content": "Reference The following notes were extracted, adjusted or extended from the following references.\n Kubernetes book by Nigel Poulton  General   The cluster is made up of one or more masters, and a bunch of nodes.\n  Package and deploy a Kubernetes application is done via a Deployment. With Deployments, we start out with our application code and we containerize it. Then we define it as a Deployment via a YAML or JSON manifest file. This manifest file tells Kubernetes two important features:\n What our app should look like – what images to use, ports to expose, networks to join, how to perform update etc. How many replicas of each part of the app to run (scale)  Then we give the file to the Kubernetes master which takes care of deploying it n the cluste\n  The API server\n  The API Server (apiserver) is the frontend into the Kubernetes control plane. It exposes a RESTful API that preferentially consumes JSON. We POST manifest files to it, these get validated, and the work they define gets deployed to the cluster.\n The cluster store  The config and state of the cluster gets persistently stored in the cluster store, which is the only stateful component of the cluster and is vital to its operation.The cluster store is based on etcd, the popular distributed, consistent and watchable key-value store. As it is the single source of truth for the cluster, you should take care to protect it and provide adequate ways to recover it if things go wrong.\n The controller manager  They tend to sit in loops and watch for changes, the aim is to make sure the current state of the cluster matches the desired state.\n The scheduler  Watches and executes new workloads.\n"
},
{
	"uri": "http://example.org/notes/go/",
	"title": "Go",
	"tags": [],
	"description": "",
	"content": "References The following notes were extracted, adjusted or extended from the following references.\n Go mastering by Mihalis Tsoukalos  General 1. Go inserts only a semicolon at the end of a \u0026ldquo;{\u0026quot;\nfunc main() { // \u0026lt;-- this will trigger error .... } func main(){ // \u0026lt;-- this will NOT trigger error .... } 2. Install and clean packages\n$ go get -v github.com/mastsoud/go/package_name ..... $ go clean -i -v -x package_name $ rm -rf ~/go/src/github.com/mastsoud/go/package_name 3. Stdin/out/err\n   Go Unix     os.Stdin stdin \u0026ndash;\u0026gt; /dev/stdin \u0026ndash;\u0026gt; /proc/self/fd/0   os.Stdout stdout \u0026ndash;\u0026gt; /dev/stdout \u0026ndash;\u0026gt; /proc/self/fd/1   os.Stderr stderr \u0026ndash;\u0026gt; /dev/stderr \u0026ndash;\u0026gt; /proc/self/fd/2    4. Reading input\npackage main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main(){ var f *os.File f = os.Stdin defer f.Close() scanner := bufio.NewScanner(f) for scanner.Scan() { fmt.Println(\u0026#34;\u0026gt;\u0026#34;, scanner.Text()) } } 5. Logs\n rsyslogd configuration  $ grep -v \u0026#34;#\u0026#34; /etc/rsyslog.conf  Syslog  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;log/syslog\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; ) func main() { programName := filepath.Base(os.Args[0]) sysLog, err := syslog.New(syslog.LOG_INFO|syslog.LOG_LOCAL7,programName) if err != nil { log.Fatal(err) } else { log.SetOutput(sysLog) } log.Println(\u0026#34;LOG_INFO + LOG_LOCAL7: Logging in Go!\u0026#34;) sysLog, err = syslog.New(syslog.LOG_MAIL, \u0026#34;Some program!\u0026#34;) if err != nil { log.Fatal(err) } else { log.SetOutput(sysLog) } log.Println(\u0026#34;LOG_MAIL: Logging in Go!\u0026#34;) fmt.Println(\u0026#34;Will you see this?\u0026#34;) } 6. Errors\n Error types  package main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; ) func returnError(a, b int) error { if a == b { err := errors.New(\u0026#34;Error in returnError() function!\u0026#34;) return err } else { return nil } } func main() { err := returnError(1, 2) if err == nil { fmt.Println(\u0026#34;returnError() ended normally!\u0026#34;) fmt.Println(err) } err = returnError(10, 10) if err == nil { fmt.Println(\u0026#34;returnError() ended normally!\u0026#34;) } else { fmt.Println(err) } if err.Error() == \u0026#34;Error in returnError() function!\u0026#34; { fmt.Println(\u0026#34;!!\u0026#34;) } }  Typical handling of errors  if err != nil { fmt.Println(err) or log.Println(err) or panic(err) os.Exit(10) }  Example  package main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { if len(os.Args) == 1 { fmt.Println(\u0026#34;Please give one or more floats.\u0026#34;) os.Exit(1) } arguments := os.Args var err error = errors.New(\u0026#34;An error\u0026#34;) k := 1 var n float64 for err != nil { if k \u0026gt;= len(arguments) { fmt.Println(\u0026#34;None of the arguments is a float!\u0026#34;) return } n, err = strconv.ParseFloat(arguments[k], 64) k++ } min, max := n, n for i := 2; i \u0026lt; len(arguments); i++ { n, err := strconv.ParseFloat(arguments[i], 64) if err == nil { if n \u0026lt; min { min = n } if n \u0026gt; max { max = n } } } fmt.Println(\u0026#34;Min:\u0026#34;, min) fmt.Println(\u0026#34;Max:\u0026#34;, max) } 7. Using docker\n Dockerfile  FROM golang:alpine RUN mkdir /files COPY hw.go /files WORKDIR /file RUN go build -o /files/hw hw.go ENTRYPOINT [\u0026#34;/files/hw\u0026#34;] $ docker build -t go_hw:v1 . $ docker run go_hw:v1 Go internals 1. Go compiler\n Compiling source file and generate Object code.  $ go tool compile sourceFile.go $ ls -ltr sourceFile.o # This is not executable.  Genereate an object file instaed of object code  $ go tool compile -pack sourceFile.go $ ls -ltr sourceFile.a  The following will list the content of *.a file.  $ ar t sourceFile.a __.PKGDEF _go_.o  To detect trace conditions  $ go tool compile -race sourceFile.a  Showing assembly code  $ go tool compile -S sourceFile.go os.(*File).close STEXT dupok nosplit size=26 args=0x18 locals=0x0 0x0000 00000 (\u0026lt;autogenerated\u0026gt;:1)\tTEXT\tos.(*File).close(SB), DUPOK|NOSPLIT|ABIInternal, $0-24 0x0000 00000 (\u0026lt;autogenerated\u0026gt;:1)\tPCDATA\t$0, $-2 0x0000 00000 (\u0026lt;autogenerated\u0026gt;:1)\tPCDATA\t$1, $-2 0x0000 00000 (\u0026lt;autogenerated\u0026gt;:1)\tFUNCDATA\t$0, gclocals·e6397a44f8e1b6e77d0f200b4fba5269(SB) 0x0000 00000 (\u0026lt;autogenerated\u0026gt;:1)\tFUNCDATA\t$1, gclocals·69c1753bd5f81501d95132d08af04464(SB) 0x0000 00000 (\u0026lt;autogenerated\u0026gt;:1)\tFUNCDATA\t$2, gclocals·9fb7f0986f647f17cb53dda1484e0f7a(SB) 0x0000 00000 (\u0026lt;autogenerated\u0026gt;:1)\tPCDATA\t$0, $1 0x0000 00000 (\u0026lt;autogenerated\u0026gt;:1)\tPCDATA\t$1, $1 0x0000 00000 (\u0026lt;autogenerated\u0026gt;:1)\tMOVQ\t\u0026#34;\u0026#34;..this+8(SP), AX 0x0005 00005 (\u0026lt;autogenerated\u0026gt;:1)\tMOVQ\t(AX), AX 0x0008 00008 (\u0026lt;autogenerated\u0026gt;:1)\tPCDATA\t$0, $0 0x0008 00008 (\u0026lt;autogenerated\u0026gt;:1)\tPCDATA\t$1, $0 0x0008 00008 (\u0026lt;autogenerated\u0026gt;:1)\tMOVQ\tAX, \u0026#34;\u0026#34;..this+8(SP) 0x000d 00013 (\u0026lt;autogenerated\u0026gt;:1)\tXORPS\tX0, X0 ... 2. Garbage collector\n Example of GC  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;time\u0026#34; ) func printStats(mem runtime.MemStats) { runtime.ReadMemStats(\u0026amp;mem) fmt.Println(\u0026#34;mem.Alloc:\u0026#34;, mem.Alloc) fmt.Println(\u0026#34;mem.TotalAlloc:\u0026#34;, mem.TotalAlloc) fmt.Println(\u0026#34;mem.HeapAlloc:\u0026#34;, mem.HeapAlloc) fmt.Println(\u0026#34;mem.NumGC:\u0026#34;, mem.NumGC) fmt.Println(\u0026#34;-----\u0026#34;) } func main() { var mem runtime.MemStats printStats(mem) for i := 0; i \u0026lt; 10; i++ { s := make([]byte, 50000000) // memory allocation if s == nil { fmt.Println(\u0026#34;Operation failed!\u0026#34;) } } printStats(mem) for i := 0; i \u0026lt; 10; i++ { s := make([]byte, 100000000) // MORE memory allocation if s == nil { fmt.Println(\u0026#34;Operation failed!\u0026#34;) } time.Sleep(5 * time.Second) } printStats(mem) } $ go run gColl.go  To get MORE information  $ GODEBUG=gctrace=1 go run gColl.go gc 1 @0.027s 0%: 0.048+0.72+0.007 ms clock, 0.38+0.18/0.62/1.1+0.057 ms cpu, 4-\u0026gt;4-\u0026gt;0 MB, 5 MB goal, 8 P gc 2 @0.047s 0%: 0.006+0.56+0.007 ms clock, 0.055+0.39/0.69/0.79+0.061 ms cpu, 4-\u0026gt;4-\u0026gt;0 MB, 5 MB goal, 8 P gc 3 @0.060s 1%: 0.16+1.0+0.011 ms clock, 1.2+1.3/1.1/0.13+0.093 ms cpu, 4-\u0026gt;4-\u0026gt;0 MB, 5 MB goal, 8 P gc 4 @0.069s 1%: 0.016+0.54+0.016 ms clock, 0.13+0.16/0.61/1.0+0.12 ms cpu, 4-\u0026gt;4-\u0026gt;0 MB, 5 MB goal, 8 P gc 5 @0.073s 1%: 0.002+0.37+0.003 ms clock, 0.023+0/0.37/1.0+0.028 ms cpu, 4-\u0026gt;4-\u0026gt;0 MB, 5 MB goal, 8 P gc 6 @0.076s 1%: 0.016+0.41+0.011 ms clock, 0.13+0.14/0.60/0.40+0.088 ms cpu, 4-\u0026gt;4-\u0026gt;1 MB, 5 MB goal, 8 P gc 7 @0.079s 1%: 0.002+0.34+0.010 ms clock, 0.020+0.14/0.36/0.82+0.081 ms cpu, 4-\u0026gt;4-\u0026gt;0 MB, 5 MB goal, 8 P # command-line-arguments gc 1 @0.001s 10%: 0.002+1.3+0.011 ms clock, 0.018+0.82/1.4/2.0+0.092 ms cpu, 5-\u0026gt;6-\u0026gt;6 MB, 6 MB goal, 8 P gc 2 @0.010s 7%: 0.004+3.4+0.011 ms clock, 0.036+0.42/5.3/3.8+0.090 ms cpu, 13-\u0026gt;14-\u0026gt;13 MB, 14 MB goal, 8 P gc 3 @0.044s 4%: 0.017+4.8+0.011 ms clock, 0.13+0.18/8.2/18+0.093 ms cpu, 25-\u0026gt;25-\u0026gt;23 MB, 26 MB goal, 8 P mem.Alloc: 125896 Taking the example of \u0026ldquo;4-\u0026gt;4-\u0026gt;0\u0026rdquo;:\n - The first number is the heap size when the garbage collector is about to run. - The second value is the heap size when the garbage collector ends its operation. - The last value is the size of the live heap  3. GC internals\nGC in slices\nGC in maps\nGC in maps without pointers\nGC in spliting maps\nGC comparisons`\nGC unsafe code\nGC unsafe package\nDefer keyword\nDefer keyword using logging\nPanic\nRecover\nStrace\ndtrace\nGo environment\nNode trees\nGo build\nWebAssembly code\nData types 1. Slices\n  Slices are passed by reference to functions.\n  Slices are often used, more than arrays.\n  mySlcie := []int{1,23,4} mySlice := make([]int, 20) // Go initilise with default values mySlice = append(mySlice, 2134) len(mySlice) fmt.Println(mySlice[1:3])  Re-slicing may cause some problems.  Reslice do not copy values, reslice keeps reference from the orignal slice. Therefore, if you make any change of values in the reslice, they will also change values in the original slice.\npackage main import \u0026#34;fmt\u0026#34; func main() { s1 := make([]int, 5) reSlice := s1[1:3] // Reslice not copy from s1, it make reference fmt.Println(s1) fmt.Println(reSlice) reSlice[0] = -100 // This means also s[1]=-100 reSlice[1] = 123456 // This also means s[2]=123456 fmt.Println(s1) fmt.Println(reSlice) } Output\n$ go run reslice.go [0 0 0 0 0] [0 0] [0 -100 123456 0 0] [-100 123456]   If the length and the capacity of a slice have the same values and you try to add another element to the slice, the capacity of the slice will be doubled whereas its length will be increased by one.\n  Byte slices\n  s := make([]byte,5) **2. Copy slices** - Becareful using copy(destination, source), as copy() copies the minimum number of len(dst) and len(src) elements **3. Sort slice** **4. Appending arrays to slices** **5. Maps** - Declaration ```bash iMap = make(map[string]int) delete(mapName, Key) for key, value := range iMap { fmt.Println(key, value) } The bad thing is that if you try to get the value of a map key that does not exist in the map, you will end up getting zero, which gives you no way of determining whether the result was zero because the key you requested was not there or because the element with the corresponding key actually had a zero value. This is why we have _, ok in maps.\n_, ok := iMap[\u0026#34;doesItExist\u0026#34;] if ok { fmt.Println(\u0026#34;Exists!\u0026#34;) } else { fmt.Println(\u0026#34;Does NOT exist\u0026#34;) } Please note that you cannot and should not make any assumptions about the order the map pairs are going to be displayed on your screen because that order is totally random.\nThe next Go code will not work because you have assigned the nil value to the map you are trying to use:\naMap := map[string]int{} // var aMap map[string]int aMap = nil fmt.Println(aMap) aMap[\u0026#34;test\u0026#34;] = 1 Saving the preceding code to failMap.go and trying to compile it will generate the next error message:\n$ go run failMap.go map[] panic: assignment to entry in nil map This means that trying to insert data to a nil map will fail. However, looking up, deleting, finding the length, and using range loops on nil maps will not crash your code.\n6. Constants\n7. Pointers\nWhen working with pointers, you need * to get the value of a pointer, which is called dereferencing the pointer, and \u0026amp; to get the memory address of a non-pointer variable\npackage main import ( \u0026#34;fmt\u0026#34; ) func getPointer(n *int) { *n = *n * *n fmt.Println(\u0026amp;n) } func returnPointer(n int) *int { v := n * n return \u0026amp;v } func main(){ n:=3 getPointer(\u0026amp;n) fmt.Println(n) k := returnPointer(12) fmt.Println(*k) fmt.Println(k) } Pointers allow you to share data, especially between Go functions. Pointers can be extremely useful when you want to differentiate between a zero value and a value that is not set\nTime\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main(){ fmt.Println(time.Now()) time.Sleep(time.Second*2) t:=time.Now() fmt.Println(t.Day(),t.Month(), t.Year()) t2:=time.Now() fmt.Println(t2.Sub(t)) fmt.Println(\u0026#34;time units\u0026#34;, time.Nanosecond , time.Microsecond , time.Millisecond , time.Minute , time.Hour) }  Parsing date +time from a string:     CODE Meaning     2006 Year   Jan Month   02 Day   15 Hour   04 Minute   05 Second    package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main(){ test:=\u0026#34;20201025 15:20:33\u0026#34; d,_:=time.Parse(\u0026#34;20060102 15:04:05\u0026#34;,test) fmt.Println(d.Hour(),d.Minute(),d.Second()) fmt.Println(d.Year(),d.Month(),d.Day()) }  Measure time execution  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main(){ start:=time.Now() time.Sleep(time.Second) fmt.Println(time.Since(start)) } Composite Types 1. Struct\npackage main import ( \u0026#34;fmt\u0026#34; ) type XY struct{ x int y int } func returnPointer(x,y int) *XY { x++ y++ return \u0026amp;XY{x,y} } func returnStruct(x,y int) XY { x-- y-- return XY{x,y} } func main(){ s1:=returnPointer(3,4) s2:=returnStruct(3,4) fmt.Println((*s1).x) // You need a pointer reference in this case fmt.Println(s2.x) } 2. Tuples\npackage main import ( \u0026#34;fmt\u0026#34; ) func retThree(x int) (int, int, int) { return 2 * x, x * x, -x } func main() { fmt.Println(retThree(10)) n1, n2, n3 := retThree(20) fmt.Println(n1, n2, n3) n1, n2, n3 = n3,n2,n1 //swap fmt.Println(n1, n2, n3) } **3. Json\u0026#34;\u0026#34; **4. XML\u0026#34;\u0026#34; - ### Data Structures ### Functions **1. Return values of function ```bash func namedMinMax(x, y int) (min, max int) { if x \u0026gt; y { min = y max = x } else { min = x max = y } return } Note that the return as this function has named return values in its signature, the min and max parameters are automatically returned in the order in which they were put into the function definition.\n2. FUcntions with pointer parameters\nfunc getPtr(v *float64) float64 { return *v * *v } func main() { x := 12.2 fmt.Println(getPtr(\u0026amp;x)) } 3. Functions that return pointers\nfunc returnPtr(x int) *int { y := x * x return \u0026amp;y } func main() { sq := returnPtr(10) fmt.Println(\u0026#34;sq value:\u0026#34;, *sq) fmt.Println(\u0026#34;sq memory address:\u0026#34;, sq) } 4. Functions that return other functions\nfunc funReturnFun() func() int { i := 0 return func() int { i++ return i * i } } func main() { i := funReturnFun() j := funReturnFun() mt.Println(\u0026#34;1:\u0026#34;, i()) fmt.Println(\u0026#34;2:\u0026#34;, i()) fmt.Println(\u0026#34;j1:\u0026#34;, j()) fmt.Println(\u0026#34;j2:\u0026#34;, j()) fmt.Println(\u0026#34;3:\u0026#34;, i()) } Executing returnFunction.go will produce the following output:\n$ go run returnFunction.go 1: 1 2: 4 j1: 1 j2: 4 3: 9 As you can see from the output of returnFunction.go , the value of i in funReturnFun() keeps increasing and does not become 0 after each call either to i() or j() .\n5. Functions that accept other functions as paramters\nfunc function1(i int) int { return i + i } func function2(i int) int { return i * i } func funFun(f func(int) int, v int) int { return f(v) } func main() { fmt.Println(\u0026#34;function1:\u0026#34;, funFun(function1, 123)) fmt.Println(\u0026#34;function2:\u0026#34;, funFun(function2, 123)) fmt.Println(\u0026#34;Inline:\u0026#34;, funFun( func(i int) int { return i * i*i }, 123)) } Executing funFun.go will produce the next output:\n$ go run funFun.go function1: 246 function2: 15129 Inline: 1860867 6. Varadic functions\nfunc varFunc(input ...string) { fmt.Println(input) } func oneByOne(message string, s ...int) int { # accepts a single string and a variable number of integer arguments. fmt.Println(message) sum := 0 for i, a := range s { fmt.Println(i, a) sum = sum + a } s[0] = -1000 return sum } func main() { arguments := os.Args varFunc(arguments...) sum := oneByOne(\u0026#34;Adding numbers...\u0026#34;, 1, 2, 3, 4, 5, -1, 10) fmt.Println(\u0026#34;Sum:\u0026#34;, sum) s := []int{1, 2, 3} sum = oneByOne(\u0026#34;Adding numbers...\u0026#34;, s...) fmt.Println(s) } The input function argument is a slice and will be handled as a slice inside the varFunc() function. The \u0026hellip; operator used as \u0026hellip;Type is called the pack operator, whereas the unpack operator ends with \u0026hellip; and begins with a slice. A variadic function cannot use the pack operator more than once.\nBuilding and executing variadic.go will generate the following output:\n$ ./variadic 1 2 [./variadic 1 2] Adding numbers... 0 1 1 2 2 3 3 4 4 5 5 -1 6 10 Sum: 24 Adding numbers... 0 1 1 2 2 3 [-1000 2 3] "
},
{
	"uri": "http://example.org/devops/gcp/fundamentals/",
	"title": "Fundamentals",
	"tags": [],
	"description": "",
	"content": "Introduction GCP offers four main services:\n- Compute - Storage - Big data - Machine learning  The fundamentals course covers mainly the first two plus networking.\nCloud computing is an on-demand infrastrucuture available under the following characteristics:\n- Compute resouces on-demand self-service: no human intervention - Access from anywhere in the internet - Resource pooling: GCP provides share-base resources - Rapid elasiticity: Get more resources quickly as needed - Measured service: pay for what you consume or use  There are serveral GCP computing services, such as:\n- IaaS: where you pay for what you allocated - PaaS: where you pay for what you use  GCP allocation:\n- Zone: Deploymenat area, not geographically related. A zone is a single failure domain witdh in a region. - Region: Group of zone, independen geographical areas.  The basics To work in GCP you organise your work load in projects. These projects organize GCP resorues with common basic objectives. Access to GCP is through IAM, GCP ID and Access Management, and it defifnes who can do what.\nUser interfaces to access and interact with GCP includes:\n- Web interface ( GCP console and generally used at the begining ) - SDK ( gcloud, gsutil for cloud storage, bq for Big query ) - Command line ( cloud shell ) - RESTful API ( uses JSON and OAuth 2.0 authentication and authorization ) - Mobile App  All resources in GCP are organised into projects.Optionally, this projects can be organised into folder and subfolders. All these projects, folders and subfolders that belongs to an organisation can be brought under an organisation node. Each project is separated compartiment and usually have the following id:\n- Project ID: Global inmutable unique name chosen by you. - Project name: Can be mutable and chosen by you. - Project number: Global inmutable number given by GCP.  On the other hand, a policy is set on a resource, where each policy contains a set of roles and role members. Resources inherit policies from parents, where a less restrictive policy overrides a more restrictive resource policy. For example, if a organisation node policy is set to read only, but a project policy is set to read and write, then read and write is possible for that project. Take in mind this when you design your policies.\nThe Identity and Access Management, IAM, helps to manage access rights to currents users of a project. There are three parts:\n- Who: Identifies the user or resource, such as google or service account, group, domain. - How/when: This uses AIM Role, a collection of permissions: primitive, predefined, and custom. - Primitive are broad an include: owner, editor , viewer and billing administrator. - Predefined: Pre designed rules that can be used. - Custom: Where you design and set your own roles. - What: GCP Resource.  Note to give access permissions to a VM you need to use a service account.\nGCP Launcher is a quick tool for deployment that contains a pre-packaged and ready-to-deploy solutions. Some of these solutions are offered by Google and others by third-party vendors. GCP upgrades on the VMs do not update installed packages, but GCP allows you to maintain them.\nVirtual Private Cloud (VCP) network VCP is a set of one or many virtual machines interconnected through a virtual network inside your project in GCP. It is similar to a traditional network where you can define your own firewall rules to restrict access to internal resources or create static routes to redirect traffic to specific destination. An important feature of VCP in GCP is its global scope, which allow your virtual machines to be reachable globaly. It is possible to allocate resources in different zones or expand resources, such as storage or network, to any virtual machine inside your VCP. One tip at this stage is to use preemptible VMs which allows you in some extend to reduce costs.\nA VM can be creatd by console UI or by command line, gcloud. If there is not a pre-define image of your interest, you can customise your own image. Additionally, in cases such as intensive data analysis, you can use a local SSD disk. However, you need to store the data of permanent value in different place as GCP will not leave data on your local SSD disk after all process has finished. For this last case, you can use GCP persistent disks.\nAt booting time, you can als provide to GCP start-up scripts or metadata to initialise your VM. It is possible to define the number of CPUs and memory size for each VM, for example, at the time of this writing, the maximum number of CPU to provision was 96, and the maximum memory size in data was 624 GB. To complete tasks such as intensive data analytics, GCP offers auto-scale, which automatically deploys new VMs base on the load of your task. Additionally, GCP offers cloud load balancing base on the incoming traffic. The options that GCP offer for cross regional load balancing are:\n- Global HTTP(s): Layer 7 load balancing based on load. It routes different URLs to different backends. - Global SSL proxy: Layer 4 load balancing for non-HTTPS SSL traffic. - Global TCP proxy: Layer 4 load balancing of non-SSL TCP traffic. - Regional: Load balancing of any traffic, TCP and UDP on any port. - Regional internal: Load balancing of traffic inside a VPC. All options have this option.  Inside a VCP, GCP already set up a firewall and routers, you do not need to provision these resources manually. However, you can configurate them as you need. This feature comes automatically because VCP networks belong to GCP projects. In case you need to allow communication between two VCP from different GCP project, you can use VCP peering. Additonally, you can difine access rules between VCPs using VCP sharing, which define who and what can be accessed from one VCP to another.\nOn the other hand, GCP offers also Cloud DNS, which can be manage programatically through its API or by command line. You can manage zones, which includes edit, add, remove DNS entries. Finally, Cloud CDN is able to cache your content close to your clients.\nNote that in the case you want to interconnect with external networks or your own local network, GCP offers the following options:\n- VPN: Through a cloud router using Boarder Gateway protocol. This means you access your GCP through internet. - Direct peering: This is private connection between your network and GCP. This is not cover GCP SLA. - Carried peering: Connection through the largest partner network of service providers. - Dedicated Interconnect: Connects nx10G transport circuit for private cloud traffic.  How to create a VM using UI console\n1. Login to GCP console --\u0026gt; Click product and services --\u0026gt; Compute Engine --\u0026gt; VM instances --\u0026gt; create. 2. Edit name, zone, VM specs as you need --\u0026gt; Click create. How to create a VM by command line\n1. Click on Activate Google Cloud shell ( icon on the top bar ) 2. $gcloud compute zones list # List all available zones 3. $gcloud config set compute/zone us-central1-c # Sets the zone  4. $gcloud compute instances create \u0026#34;MYVM\u0026#34; \\ --machine-type \u0026#34;n1-standard-1\u0026#34; \\ --image-project \u0026#34;debian-cloud\u0026#34; \\ --image \u0026#34;debian-9-stretch-v20170918\u0026#34; \\ --subnet \u0026#34;default\u0026#34; Basic inspection\n- You can ssh into your VM by click on the SSH in the console interface. - You can ssh from one VM to another by ssh \u0026lt;NAME_VM\u0026gt; directly. - You can install a web server, such as nginx-light, and use http to retrieve content. - Use sudo to have admin privileges without a password. Storage You can store data inside the VMs you ship in GCP. However, GCP can store structured, unstructured, transactional and relational data throught the following services:\n- Cloud storage - CLoud SQL - Cloud Spanner - Cloud Data Store - Google Big Table Cloud storage Cloud storage uses object storages to store your data. Object storage is not same as the traditional file storage or block storage. Instead, the whole object is stored by associating it to a key, a key that has a URL form.\nCloud storage is a set of buckets, that are inmutable, which means that you can not edit them, but you can create a new version of them. Cloud storage always encrypt your data in the server side.\nEach bucket has a unique id and location. You can move one bucket from one location to another in order to optimise latency. To control access to your buckets you can use Cloud IAM, which in general is sufficient. Each of the access control lists, ACLs, have two parts: one to specify the user or group of users and the other to specify the type of permissions associated to these users or groups.\nAdditionaly, you can turn on versioninng, which allows you track all modifcations of you object storage. However, if you turn off your versioning, you will always have one version of your object storage, which means that the old version will be replaced by the new one.\nGCP offers four Cloud storage classes:\n- Regional(99.95% availability): Let your store your data in a specific region. Cheaper but less redundant. Examples include: Europe west, asia east. - Multi-regional(99.90% availability): Stores your date in a at least two geographica regions separated by at lease 160 km. Examples include: EU, Asia. Ideal for data frequently accessed. - Nearline(99.00% availability): It is a low cost and ideal for unfrequently accessed data, such as once a month or lest on average. - Coldline(99.00% availability): It is a very low cost and ideal for data accessed less than once a year, such as archiving, online backups and disaster recovery. There are several methods to transfer your data into Cloud storage. These methods include gs-util, drag and drop, online transfer storage service and the offline transfer appicanes tools. Cloud Storage also works with other GCP services to transfer your data, these services include import export tables using BigQuery and cloud SQL, Object storage, logs and backups from App engines, scripts and images from Compute Engine.\nGoogle Big Table\nIt is a NOSQL Big Data database service. Bigtable can scale to billonw of rows and thousands of columns allowing you to store petabytes of data. It is ideal for storing large set of data with low latency, it support high throughput to both read and write, which make it a good choice for operational and analytical analysis.\nIt uses the same open source API as HBase. The advantages of using Bigtable over Hbase are:\n- Scalability: especially when query rates per time increases, GCP manages to scale up your cluster through a machine counter. - Administration: These tasks are transparent to the user, and GCP manages all operational work such as updates, and patches. - Encryption: Data is encrypted in both in-flight and at rest. Also IAM permissions can be applied to RBAC to Bigtable data. - GCP: Bigtable is same data base used by Google\u0026#39;s core services such as search, analytics and maps. Bigtable can be accessed by the following patterns:\n- App API: You can write and read from Bigtable using service layer like VMs, HBase REST server or Java server through HBase client. - Streaming: You can use popular tools such as Cloud Dataflow, Spark Streaming and Storm. - Batches: You can read and write using Hadoop Mapreduce, Dataflow, or Spark. CLoud SQL\nThis is a RDBMS service. Offers MySQL or PostgreSQL databases as service. The benefits of using Cloud SQL rather than set my own database in the cloud, is that Cloud SQL offers:\n- Automatic replication: read, failover and external replicas. This means that Cloud SQL can replicate data within multiple zones without failover. - Backups: Cloud SQL offers you backup your data on-demand or base on schedules. The backup could be vertical, by changing the machine type, or horizontal via read replicas. - Security: Cloud SQL includes network firewalls, customer data encryption when data is in internal Google\u0026#39;s networks. - Visibility: Cloud SQL instances are accessible by other GCP or external services. Cloud SQL can be used with App Engine application. Compute engine instances can be authorized to access Cloud SQL using external IP address and also can be configured with a preferred zone. Additionaly, Cloud SQL can be adminnistrated by external tools or can be set external replicas.  Cloud Spanner\nCloud Spanner offers an horizontal scalability for Cloud SQL. It offers transactional consistency at global scale, schemas , SQL and automatic synchronous replication for high availability. Cloud Spinner can be consider when you have an outgrown any relational database or you need glocal data transactional consistency such as the cases of financial application and inventory applications.\nCloud DataStore\nIt is another high scalable NOSQL database service. Its main case is to store structured data from App Engine applications. Cloud DataStore automaticaly handles replications and sharding.\nSummary\nThe following figures present a summary of technical differences between GCP services and their common use cases.\nNote: These figures are screenshots took during the course. Credits to GCP training material\nHow to get started with Cloud Storage and Cloud SQL  Create a VM with an Apache web server and upload an image to a new bucket.  - Create a VM as it was described on section \u0026#34;how to create a VM ...\u0026#34;. Before click create please add a start up script that install a web server in this VM by expanding the link \u0026#34;management, disks, networking, SSH keys\u0026#34; and look for the \u0026#34;Startup script\u0026#34;. You can copy the following: apt update apt isntall apache2 php php-mysql -y service apache2 restart - Create a bucket and upload any image to this bucket. You can click on cloud shell and type: $ gsutil mb -l EU gs://$DEVSHELL_PROJECT_ID # This creates a bucket with an UNIQUE ID,my google project id $ gsutil cp gs://cloud-training/gcpfxi/my-excellent-blog.png my-image-blog.png # Copy an image to my local VM $ ls # This should show that the images is in your VM now. $ gsutil cp my-image-blog.png gs://$DEVSHELL_PROJECT_ID/my-image-blog.png # This uploads my image to my bucket. $ gsutil acl ch -u allUsers:R gs://$DEVSHELL_PROJECT_ID/my-excellent-blog.png # modify access permissions $ gsutil ls gs://$DEVSHELL_PROJECT_ID # will show you the content of your bucket, not VM. Also you can see open your bucket using the GUI and see if it is there. To do so, click on Storage -\u0026gt; Browser -\u0026gt; Click on the name of the bucket. In here check the box for \u0026#34;Share plublicly\u0026#34;. Please, copy the link somewehre we will use it to point from the index.php page of this webserver. Create SQL instance  - Click on Products and Services -\u0026gt; Storage -\u0026gt; SQL - \u0026gt; Create Instance -\u0026gt; MySQL - Give a name of this instance and set a password. Remember to choose the same ZONE as the VM on step 1. Click create. - Click on the name and create an account: click on users -\u0026gt; create users -\u0026gt; type user name and password -\u0026gt; Click create. - Restrict the access to this SQL instance to VM on point 1. Click authorization -\u0026gt; add network -\u0026gt; Give a name -\u0026gt; Copy the publick IP address of the VM on point 1. Remember add /32 as mask for the public IP address, this is to protect from broad internet access. Configure your Apache main page  - Login to the VM created on point 1 using SSH. - Edit the /var/www/html/index.php and add php code to connect to the DB of point 2 and show the image uploaded in point 1. - Restart Apache and open in a browser \u0026#34;public ip address of VM\u0026#34;/index.php. You should be able to see the image we uploaded on point 1 and see a connection succed message to the SQL instance. As a quick example here some tips: html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;Welcome to my excellent blog\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;img src=\u0026#39;https://storage.googleapis.com/qwiklabs-gcp-0005e186fa559a09/my-excellent-blog.png\u0026#39;\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to my excellent blog\u0026lt;/h1\u0026gt; \u0026lt;?php $dbserver = \u0026#34;CLOUDSQLIP\u0026#34;; $dbuser = \u0026#34;blogdbuser\u0026#34;; $dbpassword = \u0026#34;DBPASSWORD\u0026#34;; // In a production blog, we would not store the MySQL // password in the document root. Instead, we would store it in a // configuration file elsewhere on the web server VM instance. $conn = new mysqli($dbserver, $dbuser, $dbpassword); if (mysqli_connect_error()) { echo (\u0026#34;Database connection failed: \u0026#34; . mysqli_connect_error()); } else { echo (\u0026#34;Database connection succeeded.\u0026#34;); } ?\u0026gt; \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt; Containers in the Cloud Applications in the Cloud Developing, Deploying and Monitoring in the Cloud Big Data and Machine Learning in the Cloud "
},
{
	"uri": "http://example.org/sre/online/sre-mmr-week4/",
	"title": "SRE MMR Week4",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://example.org/sre/online/sre-mmr-week3/",
	"title": "SRE MMR Week3",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://example.org/sre/online/sre-mmr-week2/",
	"title": "SRE MMR Week2",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://example.org/sre/online/sre-mmr-week1/",
	"title": "SRE MMR Week1",
	"tags": [],
	"description": "",
	"content": "Introduction to SRE How does SRE differ from Devops? Devops and SRE point to similar goals, which is break down organizational barriers to deliver software features faster.\nTraditionally, developers are responsable for features and operations for stability. Developers want to move faster to release new features and operations want to move slow to keep all service stable. As a commong results, tension between teams appears during realease times. Devops and SRE practices aim to break downs this tensions.\nIn general, Devops approach include the following areas:\n- Reduce organizational silos: --\u0026gt; Break down tension promotes collaboration between teams. - Accept failure as normal - Implement gradual change: --\u0026gt; Small and incremental changes are easy to review and maintain. - Leverage tooling and automation - Measure as much as you can On the other side, SRE appraoch to same areas are as following:\n- Reduce organizational silos: --\u0026gt; Operation responsability to release in production is shared with developers. - Accept failure as normal: --\u0026gt; Blameless postmordem. Failure is expected and it is hold by an error budget. - Implement gradual change: --\u0026gt; Small and incremental release, such as Canary releases. - Leverage tooling and automation: --\u0026gt; Measure toil and automate to minimise manual intervention. - Measure as much as you can: --\u0026gt; Measure toil, reliability and service. Therefore, one initial conclusion is that:\n SRE is a concrete class that implements Devops\n What is CRE? It stands for Customer Reliability Engineering and it is focus on breaking down organizational barries between service prodivers and customers. In this context, failure is pre-accepted as a conditions to enhance future cases, error budget.This pre-condition helps to minimise panic when a down time happens at the service level. Another important criteria is to implement measurements that can offer to everyone, in both sides, visibility of on how the service performs.\nHow can they help you be more reliable? In various cases, customers use provider\u0026rsquo;s services, through APIs. in different ways that are not expected by the service provider, and providers do not like to breaks the customer expectation. This sceneario is easly visible the number of customers scale up.\nCRE helps to providers to openinly communicate with customers. Clear communication of how your service was designed to behave, indirectly means to expose provider\u0026rsquo;s SRE practices, such is their SLOs, to the customers. By teaching or helping the customers to build their own SRE environment, we are teaching them how to interact correctly with our system or platform. Consequently, the real scope and limitations are presented clearly to the customer, which formilise what the customer can expect as a final result.\nIn conclusion, by sharing SRE practices with customers, not only new features can be released faster, it also enhance customer satisfactione.\nWhy Are SLOs Important for Your Organization? Targeting Reliability Introduction Promises, Promises. SLOs vs SLAs. Happiness Test. How Do We Measure Reliability? Edge Cases How Reliable Should a Service Be? Setting Targets for Reliability. Iterate! Operating for Reliability Introduction When Do We Need to Make a Service More Reliable? Error Budgets. Trading off Reliability Against Features How Do We Make a Service More Reliable? "
},
{
	"uri": "http://example.org/sre/online/",
	"title": "Online resources",
	"tags": [],
	"description": "",
	"content": "The following pages contain notes that I took from courses online. These notes are in here as way to summaries my understanding and record them as personal notes.\n* Site Reliability Engineering: Measuring and Managing Reliability by Google Cloud SRE-MMR This course is divided in four weeks.\n Week 1:  Introduction to SRE Targeting Reliability Operating for Reliability   Week 2 Week 3 Week 4  "
},
{
	"uri": "http://example.org/sre/references/",
	"title": "References",
	"tags": [],
	"description": "",
	"content": "This page present a list of references related to SRE.\nBooks   Beyer, B., Jones, C., Petoff, J. and Murphy, N.R., 2016. Site Reliability Engineering: How Google Runs Production Systems. \u0026quot; O\u0026rsquo;Reilly Media, Inc.\u0026quot;.\n A online available version can be read from here.    Beyer, B., Murphy, N.R., Rensin, D.K., Kawahara, K. and Thorne, S., 2018. The site reliability workbook: Practical ways to implement SRE. \u0026quot; O\u0026rsquo;Reilly Media, Inc.\u0026quot;.\n Online version of this book can be found in here.    Jennifer P., JC van W.,Preston Y., Jessie Y., Jesus C., and Myk T.,2020. Training Site Reliability Engineers. \u0026ldquo;O\u0026rsquo;Reilly Media, Inc.\u0026quot;.\n Online version available at here.     Papers   Sloss, B.T., Nukala, S. and Rau, V., 2019. Metrics that matter. Communications of the ACM, 62(4), pp.88-88.\n Online read in here.     Online resources   Unknown author, unkown year, SLO Workshop Google Cloud, https://www.usenix.org/sites/default/files/conference/protected-files/srecon18emea_slides_fong-jones.pdf.\n  Google Cloud, unkown year, Site Reliability Engineering: Measuring and Managing Reliability, Coursera online courses. https://www.coursera.org/learn/site-reliability-engineering-slos/home/info\n  "
},
{
	"uri": "http://example.org/tools/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "This page presents suggestions on how to install tools of interest. It is ordered alphabetically.\nA G   GO\n $ git clone https://github.com/golang/go.git $ cd go $ ./all.bash # \u0026lt;-- This should generate ../bin/go file. $ cd .. $ export GOPATH=`pwd` # \u0026lt;-- Add this to your profile such as ~/.bashrc $ cd bin $ export GOBIN=`pwd` # \u0026lt;-- Add this to your profile such as ~/.bashrc $ go version    P   Packer\n $ git clone https://github.com/hashicorp/packer.git $ cd packer $ go build -o bin/packer . # \u0026lt;-- This will create ./bin/packer executable file $ ./bin/packer version $ sudo ln -s `pwd`/bin/packer /usr/local/bin/packer # \u0026lt;-- Optional $ packer --help    V   Vi File Manager\n $ mkdir temp $ cd temp $ git clone https://github.com/vifm/vifm.git $ cd vifm $ dpkg -l | grep libncursesw5-dev # \u0026lt;-- be sure you have this package $ ./configure $ sudo make install $ vifm . # \u0026lt;-- Enjoy vi File Manager    Z "
},
{
	"uri": "http://example.org/research/nmanet/",
	"title": "NManet",
	"tags": [],
	"description": "",
	"content": "Very brief overview NDN for MANETs approach, represented as nMANET, aims to offer an alternative perspective on how the characteristics of NDN can be utilised to solve the limitations of MANETs. nMANET has its roots in Named Data Network NDN, an instance of Content Centric Networks CCN. In contrast with traditional TCP/IP networks, CCN enables content addressing instead of host based communication, and secures the content instead of securing the communication channel between hosts. Therefore the content can be obtained from the intermediate caches or final information producers.\nThough NDN has proven to be an effective design in wired networks, it does not perfectly fit in Mobile Adhoc Networks. This is due to the high mobility of mobile devices and their resource constrains such as remaining energy in batteries. nMANET intends to fill this gap by developing a prototype called JNFD and Mini-JNFD.\nMore details about the project will be released in the last trimester of 2020\n"
},
{
	"uri": "http://example.org/devops/images/",
	"title": "Building Images",
	"tags": [],
	"description": "",
	"content": "This page presents a set of templates to build images through tools such as packer. The content of these templates is the result of a combination of available resources online.\nPacker This sections present cases about how to build linux-base images. More details in the Ajayu github repository.\n Oracle Linux 6.10 using a DVD .iso file. Jenkins and Capistrano V2 base on OL6. It is also available in Vagrant Cloud  "
},
{
	"uri": "http://example.org/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://example.org/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]